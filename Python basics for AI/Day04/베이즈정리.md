# 베이즈 정리

[출처](https://angeloyeo.github.io/2020/01/09/Bayes_rule.html)

## 베이즈 정리의 의미와 의의

베이즈 정리는 새로운 정보를 토대로 어떤 사건이 발생했다는 주장에 대한 신뢰도를 갱신해 나가는 방법이다.



베이즈 정리를 이해함에 있어서 가장 먼저 정리해야 할 개념은 ‘확률’에 관한 관점이다.

우리가 아는 일반적인 확률론에서는 확률을 빈도론적인 관점으로 확률을 정의해오고 이해해왔다.

여기서는 확률이라는 단어를 ‘주장에 대한 신뢰도’로 생각해보자.

이러한 관점은 확률에 대한 베이지안 주의(Bayesianism) 관점으로 볼 수 있다.

가령 동전의 앞면이 나올 확률이 50%라고 하면, 빈도주의자들은 100번 동전을 던졌을 때 50번은 앞면이 나온다고 해석하고, 베이지안 주의자들은 동전의 앞면이 나왔다는 주장의 신뢰도가 50%라고 보는 것.

## 베이즈 정리를 하기 위한 사전 지식

#### 결합 확률

결합 확률 이란 두 개 이상의 사건이 동시에 일어날 확률을 말한다. 따라서 두 개 이상의 확률 변수를 가진다. 만약 각각의 사건이 독립이라면 다음의 조건을 만족한다.
$$
P(A, B) = P(A)P(B)
$$

#### 조건부 확률

조건부 확률은 머신러닝과 딥러닝에서 아주 중요하다. 실제로 다루는 대부분의 문제가 이에 기반을 두기 때문이다. 조건부 확률은 두 사건에 대한 확률 분포이다. 다만 독립과는 달리, 하나의 확률 변수가 주어졌을 때 다른 확률 변수에 대한 확률 분포이다.

주사위를 두 개를 던졌을 때의 사건 A, B를 가정해보자.
$$
P(A=3|B=2)
$$
이 수식은 주사위 B가 2가 나온 상황이 주어졌을 때, 주사위 A의 값이 3이 나올 확률값을 말한다.
$$
P(A|B=2)
$$
이 수식은 주사위 B가 2가 나온 상황이 주어졌을 때 주사위 A에서 얻을 수 있는 값의 분포를 말한다. 즉 A의 값이 주어지지 않았기 때문에 값을 반환하는 것이 아니라 확률 분포 함수를 반환하게 된다.

### 베이즈 정리

- 합의 법칙

$$
P(X) = \sum_Y P(X,Y)\\
P(Y) = \sum_X P(X,Y)
$$

- 곱의 법칙

$$
P(X,Y) = P(Y|X)P(X)
$$

$$
P(X|Y) = \frac{P(X,Y)}{P(Y)}\\
P(X,Y) = P(Y)P(X|Y)\\
$$



- 베이즈 정리

$$
P(Y|X) = \frac{P(X|Y)P(Y)}{P(X)}\\
P(X) = \sum_YP(X|Y)P(Y)
$$

### 

## 용어 정리

H는 Hypothesis의 약자로써 가설 혹은 ‘어떤 사건이 발생했다는 주장’을 의미한다.

거기에, 식 (1)에서 E는 Evidence의 약자로 ‘새로운 정보’를 의미한다.

따라서 P(H)는 어떤 사건이 발생했다는 주장에 관한 신뢰도,P(H|E)는 새로운 정보를 받은 후 갱신된 신뢰도를 의미한다.

그리고 P(H)P(H)와 P(H|E)P(H|E)는 각각 사전 확률, 사후 확률이라고 부르는데, 사전(事前), 사후(事後)라는 단어를 생각해본다면 어떤 일[事], 즉 여기선 **‘evidence를 관측하여 갱신하기 전 후의 내 주장에 관한 신뢰도’** 정도로 이해하면 된다.

![image-20210121135542261](C:\Users\hyunbin\AppData\Roaming\Typora\typora-user-images\image-20210121135542261.png)





## 머신러닝에서 베이즈 정리가 가지는 의의

$$
y \sim P(y|x) \\
\hat{y} \sim P(y|x;\theta)
$$

역전파를 통해 가중치를 갱신하는 과정(MLE)에서 사용된다.